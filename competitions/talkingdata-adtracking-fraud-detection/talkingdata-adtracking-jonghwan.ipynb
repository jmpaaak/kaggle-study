{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TalkingData AdTracking 데이터의 탐색적 분석 (Exploratory data analysis)\n",
    "### 0. 데이터 필드 정보\n",
    "  - `ip`: 클릭한 폰의 IP 주소\n",
    "  - `app`: 광고가 켜지는 앱의 ID\n",
    "  - `device`: 모바일 폰 타입\n",
    "  - `os`: 모바일 폰의 OS 버전\n",
    "  - `channel`: 광고 채널(e.g. facebook, google ad 등등)\n",
    "  - `click_time`: 광고를 클릭한 시간(UTC)\n",
    "  - `attributed_time`: 만약 유저가 앱을 다운로드 하였으면, 다운로드한 시간\n",
    "  - `is_attributed`: 앱의 실제 다운로드 여부를 나타냄(실제 추정 값)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background and objectives\n",
    "  #### BUILD AN ALGORITHM THAT PREDICTS WHETHER A USER WILL DOWNLOAD AN APP AFTER CLICKING A MOBILE APP AD.\n",
    "  - misleading click data and wasted money\n",
    "  - Ad channels can drive up costs by simply clicking on the ad at a large scale.\n",
    "  - 3 billion clicks/day, 90% are potentialy fraudulent.\n",
    "    - previous: measure the journey of a user's click across their portfolio, flag IP addresses who produce lots of clicks\n",
    "    - IP blacklists and device blacklist  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%html\n",
    "<!-- 에디터 폰트를 조정합니다. -->\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "    font-size: 16px;\n",
    "    font-family: Myriad Pro;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show data from the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_sample.csv.zip', 'sample_submission.csv.zip', 'test.csv', 'mnt', 'train.csv.zip', 'train.csv', 'test.csv.zip', 'talkingdata-adtracking-jongmin.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./data\"))\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path and data type definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'\n",
    "dtypes = {\n",
    "    'ip'      : 'uint32',\n",
    "    'app'     : 'uint16',\n",
    "    'device'  : 'uint16',\n",
    "    'os'      : 'uint16',\n",
    "    'channel' : 'uint16',\n",
    "    'is_attributed' : 'uint8',\n",
    "    'click_id' : 'uint32'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71807406 53016937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols = ['ip','app','device','os', 'channel', 'click_time', 'is_attributed']\n",
    "test_cols = ['ip','app','device','os', 'channel', 'click_time', 'click_id']\n",
    "train_data = pd.read_csv(path+'train.csv', dtype=dtypes, skiprows = range(1,131886954), usecols=train_cols)\n",
    "test_data = pd.read_csv(path+\"test.csv\", dtype=dtypes, usecols=test_cols)\n",
    "len_train = len(train_data)  #test data 와 train data를 섞어서 쓴다.\n",
    "train_data = train_data.append(test_data)\n",
    "print( len(train_data), len_train)\n",
    "del test_data; \n",
    "gc.collect() #garbage collections\n",
    "#skiprows: skip rows from the beginning of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_id</th>\n",
       "      <th>click_time</th>\n",
       "      <th>device</th>\n",
       "      <th>ip</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>os</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>201143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>34684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>207368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>110176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>109644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app  channel  click_id           click_time  device      ip  is_attributed  \\\n",
       "0   11      487       NaN  2017-11-09 00:00:00       1  201143            0.0   \n",
       "1    2      469       NaN  2017-11-09 00:00:00       1   34684            0.0   \n",
       "2   26      477       NaN  2017-11-09 00:00:00       1  207368            0.0   \n",
       "3   18      121       NaN  2017-11-09 00:00:00       1  110176            0.0   \n",
       "4   12      265       NaN  2017-11-09 00:00:00       1  109644            0.0   \n",
       "\n",
       "   os  \n",
       "0  13  \n",
       "1  13  \n",
       "2  19  \n",
       "3   8  \n",
       "4  19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hour, day, wday\n",
    "- click time을 hour, day, wday(요일)로 나누었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['hour'] = pd.to_datetime(train_data.click_time).dt.hour.astype('uint8')\n",
    "train_data['day'] = pd.to_datetime(train_data.click_time).dt.day.astype('uint8')\n",
    "train_data['wday'] = pd.to_datetime(train_data.click_time).dt.dayofweek.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파생 변수 만들기\n",
    "- ip-day-hour combination\n",
    "- ip-app combination\n",
    "- ip-app-os combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = train_data[['ip','day','hour','channel']].groupby(by=['ip','day','hour'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'qty'})\n",
    "train_data = train_data.merge(gp, on=['ip','day','hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.head()\n",
    "del gp; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_id</th>\n",
       "      <th>click_time</th>\n",
       "      <th>device</th>\n",
       "      <th>ip</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>os</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>wday</th>\n",
       "      <th>qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>201143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>34684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>207368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>110176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>109644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app  channel  click_id           click_time  device      ip  is_attributed  \\\n",
       "0   11      487       NaN  2017-11-09 00:00:00       1  201143            0.0   \n",
       "1    2      469       NaN  2017-11-09 00:00:00       1   34684            0.0   \n",
       "2   26      477       NaN  2017-11-09 00:00:00       1  207368            0.0   \n",
       "3   18      121       NaN  2017-11-09 00:00:00       1  110176            0.0   \n",
       "4   12      265       NaN  2017-11-09 00:00:00       1  109644            0.0   \n",
       "\n",
       "   os  hour  day  wday  qty  \n",
       "0  13     0    9     3   70  \n",
       "1  13     0    9     3   54  \n",
       "2  19     0    9     3  101  \n",
       "3   8     0    9     3  146  \n",
       "4  19     0    9     3  393  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouping by ip-app combination\n",
    "gp = train_data[['ip','app', 'channel']].groupby(by=['ip', 'app'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_count'})\n",
    "train_data = train_data.merge(gp, on=['ip','app'], how='left')\n",
    "del gp; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print('group by ip-app-os combination....')\n",
    "gp = train_data[['ip','app', 'os', 'channel']].groupby(by=['ip', 'app', 'os'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_os_count'})\n",
    "train_data = train_data.merge(gp, on=['ip','app', 'os'], how='left')\n",
    "del gp; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 타입 정리하기\n",
    "train_data['qty'] = train_data['qty'].astype('uint16')\n",
    "train_data['ip_app_count'] = train_data['ip_app_count'].astype('uint16')\n",
    "train_data['ip_app_os_count'] = train_data['ip_app_os_count'].astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "train_data[['app','device','os', 'channel', 'hour', 'day', 'wday']].apply(LabelEncoder().fit_transform)\n",
    "# print ('final part of preparation....')\n",
    "test_data = train_data[len_train:]\n",
    "train_data = train_data[:len_train]\n",
    "y_train = train_data['is_attributed'].values\n",
    "train_data.drop(['click_id', 'click_time','ip','is_attributed'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network\n",
    "- Get max from each columns\n",
    "- Model Configuration\n",
    "    - Embedding layers: Turns positive integers (indexes) into dense vectors of fixed size. eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
    "    - SpatialDropout1D\n",
    "    - 2 x Droupout\n",
    "    - Dense\n",
    "    Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_app = np.max([train_data['app'].max(), test_data['app'].max()])+1\n",
    "max_ch = np.max([train_data['channel'].max(), test_data['channel'].max()])+1\n",
    "max_dev = np.max([train_data['device'].max(), test_data['device'].max()])+1\n",
    "max_os = np.max([train_data['os'].max(), test_data['os'].max()])+1\n",
    "max_h = np.max([train_data['hour'].max(), test_data['hour'].max()])+1\n",
    "max_d = np.max([train_data['day'].max(), test_data['day'].max()])+1\n",
    "max_wd = np.max([train_data['wday'].max(), test_data['wday'].max()])+1\n",
    "max_qty = np.max([train_data['qty'].max(), test_data['qty'].max()])+1\n",
    "max_c1 = np.max([train_data['ip_app_count'].max(), test_data['ip_app_count'].max()])+1\n",
    "max_c2 = np.max([train_data['ip_app_os_count'].max(), test_data['ip_app_os_count'].max()])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769 501 4228 957 17 11 5 43959 65409 16654\n"
     ]
    }
   ],
   "source": [
    "print( max_app, max_ch, max_dev, max_os, max_h, max_d, max_wd, max_qty, max_c1, max_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        'ch': np.array(dataset.channel),\n",
    "        'dev': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'h': np.array(dataset.hour),\n",
    "        'd': np.array(dataset.day),\n",
    "        'wd': np.array(dataset.wday),\n",
    "        'qty': np.array(dataset.qty),\n",
    "        'c1': np.array(dataset.ip_app_count),\n",
    "        'c2': np.array(dataset.ip_app_os_count)\n",
    "    }\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "app (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ch (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dev (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "os (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h (InputLayer)                  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "d (InputLayer)                  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "wd (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "qty (InputLayer)                (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c1 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c2 (InputLayer)                 (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        38450       app[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 50)        25050       ch[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 50)        211400      dev[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 50)        47850       os[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 50)        850         h[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 50)        550         d[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 50)        250         wd[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 50)        2197950     qty[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 50)        3270450     c1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 50)        832700      c2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 500)       0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "                                                                 embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "                                                                 embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1, 500)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 500)          0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1000)         501000      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1000)         1001000     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1001        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,128,501\n",
      "Trainable params: 8,128,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      " - 248s - loss: 0.0083 - acc: 0.9978\n",
      "Epoch 2/2\n",
      " - 242s - loss: 0.0067 - acc: 0.9983\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`save_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b64773079076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dl_support.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   2602\u001b[0m         \"\"\"\n\u001b[1;32m   2603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2604\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2605\u001b[0m         \u001b[0;31m# If file exists and should not be overwritten:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "train_df = get_keras_data(train_data)\n",
    "\n",
    "with K.tf.device('/device:GPU:2'):\n",
    "    emb_n = 50\n",
    "    dense_n = 1000\n",
    "    in_app = Input(shape=[1], name = 'app')\n",
    "    emb_app = Embedding(max_app, emb_n)(in_app)\n",
    "    in_ch = Input(shape=[1], name = 'ch')\n",
    "    emb_ch = Embedding(max_ch, emb_n)(in_ch)\n",
    "    in_dev = Input(shape=[1], name = 'dev')\n",
    "    emb_dev = Embedding(max_dev, emb_n)(in_dev)\n",
    "    in_os = Input(shape=[1], name = 'os')\n",
    "    emb_os = Embedding(max_os, emb_n)(in_os)\n",
    "    in_h = Input(shape=[1], name = 'h')\n",
    "    emb_h = Embedding(max_h, emb_n)(in_h) \n",
    "    in_d = Input(shape=[1], name = 'd')\n",
    "    emb_d = Embedding(max_d, emb_n)(in_d) \n",
    "    in_wd = Input(shape=[1], name = 'wd')\n",
    "    emb_wd = Embedding(max_wd, emb_n)(in_wd) \n",
    "    in_qty = Input(shape=[1], name = 'qty')\n",
    "    emb_qty = Embedding(max_qty, emb_n)(in_qty) \n",
    "    in_c1 = Input(shape=[1], name = 'c1')\n",
    "    emb_c1 = Embedding(max_c1, emb_n)(in_c1) \n",
    "    in_c2 = Input(shape=[1], name = 'c2')\n",
    "    emb_c2 = Embedding(max_c2, emb_n)(in_c2) \n",
    "    fe = concatenate([(emb_app), (emb_ch), (emb_dev), (emb_os), (emb_h), \n",
    "                     (emb_d), (emb_wd), (emb_qty), (emb_c1), (emb_c2)])\n",
    "    s_dout = SpatialDropout1D(0.2)(fe) # drops entire 1D feature maps instead of individual elements\n",
    "    x = Flatten()(s_dout) \n",
    "    x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "    x = Dropout(0.2)(Dense(dense_n,activation='relu')(x))\n",
    "    outp = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inputs=[in_app,in_ch,in_dev,in_os,in_h,in_d,in_wd,in_qty,in_c1,in_c2], outputs=outp)\n",
    "\n",
    "    batch_size = 20000\n",
    "    epochs = 2\n",
    "    exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "    steps = int(len(train_df) / batch_size) * epochs\n",
    "    lr_init, lr_fin = 0.001, 0.0001\n",
    "    lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "    optimizer_adam = Adam(lr=0.001, decay=lr_decay)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer_adam,metrics=[''])\n",
    "    model.summary()\n",
    "    model.fit(train_df, y_train, batch_size=batch_size, epochs=2, shuffle=True, verbose=2)\n",
    "    del train_df, y_train; gc.collect()\n",
    "    model.save_weights('dl_support.h5')\n",
    "\n",
    "    sub = pd.DataFrame()\n",
    "    sub['click_id'] = test_df['click_id'].astype('int')\n",
    "    test_df.drop(['click_id', 'click_time','ip','is_attributed'],1,inplace=True)\n",
    "    test_df = get_keras_data(test_df)\n",
    "\n",
    "    print(\"predicting....\")\n",
    "    sub['is_attributed'] = model.predict(test_df, batch_size=batch_size, verbose=2)\n",
    "    del test_df; gc.collect()\n",
    "    print(\"writing....\")\n",
    "    sub.to_csv('dl_support.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
